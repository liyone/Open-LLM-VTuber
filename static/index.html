<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Open-LLM-VTuber</title>



    <!-- pixi live2d dependencies -->
    <!-- Load Cubism and PixiJS -->
    <!-- <script src="https://cubism.live2d.com/sdk-web/cubismcore/live2dcubismcore.min.js"></script> -->
    <script src="libs/live2dcubismcore.min.js"></script>
    <!-- <script src="https://cdn.jsdelivr.net/gh/dylanNew/live2d/webgl/Live2D/lib/live2d.min.js"></script> -->
    <script src="libs/live2d.min.js"></script>
    <!-- <script src="https://cdn.jsdelivr.net/npm/pixi.js@7.x/dist/pixi.min.js"></script> -->
    <script src="libs/pixi.min.js"></script>

    <!-- <script src="https://cdn.jsdelivr.net/gh/RaSan147/pixi-live2d-display@v0.5.0-ls-7/dist/index.min.js"></script> -->
    <script src="libs/index.min.js"></script>



    <script src="TaskQueue.js"></script>

    <!-- Voice Activation Detection -->
    <!-- <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/ort.js"></script> -->
    <script src="libs/ort.js"></script>
    <!-- <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.7/dist/bundle.min.js"></script> -->
    <script src="libs/bundle.min.js"></script>

    <link rel="stylesheet" href="index.css">

    <style>
        /* Add these styles to your existing CSS */
        .text-input-container {
            display: flex;
            gap: 10px;
            margin: 15px 0;
            padding: 15px;
        }

        #textInput {
            flex-grow: 1;
            padding: 12px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 30px;
        }

        #sendButton {
            padding: 8px 16px;
            background-color: #4CAF50;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 30px;
        }

        #sendButton:hover {
            background-color: #45a049;
        }

        .user-message-container {
            background-color: rgba(0, 0, 0, 0.6);
            padding: 15px;
            margin: 10px 0;
            border-radius: 4px;
            min-height: 50px;
            max-height: 100px;
            overflow-y: auto;
            font-size: 30px;
        }

        .user-message-label {
            color: #4CAF50;
            font-weight: bold;
            margin-right: 8px;
            font-size: 30px;
        }

        .user-message {
            color: white;
            font-size: 30px;
        }

        /* Update the bot message styles */
        .fixed-bottom {
            min-height: 60px;
            max-height: 420px;
            padding: 15px;
            margin: 10px 0;
            overflow-y: auto;
            background-color: rgba(0, 0, 0, 0.6);
            border-radius: 4px;
            color: white;
            font-size: 40px;
        }

        .twitch-notes {
            color: #ffffff;
            font-size: 40px;
            margin-top: 5px;
            background-color: rgba(0, 0, 0, 0.6);
            padding: 10px;
            border-radius: 4px;
            font-weight: bold;
            width: 400px;
            word-wrap: break-word;
            white-space: normal;
        }

        .top-right {
            position: fixed;
            top: 220px;
            right: 500px;
            z-index: 1000;
        }

        .vision-container {
            background-color: rgba(0, 0, 0, 0.6);
            padding: 15px;
            border-radius: 8px;
            width: 400px;
            margin: 10px 0;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.3);
            display: flex;
            justify-content: center;
            align-items: center;
        }

        .iframe-container {
            background-color: rgba(0, 0, 0, 0.6);
            padding: 15px;
            border-radius: 8px;
            width: 400px;
            height: 400px;
            margin-top: 10px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.3);
            display: flex;
            justify-content: center;
            align-items: center;
            overflow: hidden;
        }

        #uploadedImage {
            max-width: 100%;
            height: auto;
            border-radius: 6px;
            display: none;
            margin: 0 auto;
            object-fit: contain;
        }

        #toggleMessageBox {
            position: fixed;
            top: 20px;
            right: 30px;
            z-index: 1001;
        }

        #displayIframe {
            width: 400px;
            height: 400px;
            border-radius: 6px;
            display: none;
            border: none;
        }

        /* Hide containers when their content is hidden */
        .vision-container:not(:has(#uploadedImage[style*="display: block"])) {
            display: none;
        }

        .iframe-container:not(:has(#displayIframe[style*="display: block"])) {
            display: none;
        }

        /* Add to your existing styles */
        .ui-hidden {
            display: none !important;
        }
        
        .top-left {
            position: fixed;
            top: 20px;
            left: 30px;
            z-index: 1000;
            display: flex;
            flex-direction: column;
            gap: 5px;
        }
        
        .top-left > *:not(.twitch-notes) {
            margin-bottom: 5px;
        }
    </style>
    <script src="randomPrompts.js"></script>
    <script src="twitchWs.js"></script>
</head>

<body>
    <div class="top-left">
        <button id="wsStatus">Disconnected</button>
        <button id="stateDisplay">Status: loading</button>
        <input type="text" id="wsUrl" placeholder="WebSocket URL">
        <input type="text" id="twitchChannel" placeholder="Twitch Channel">
        <button id="twitchConnect">Connect to Twitch</button>
        <div class="twitch-notes">
            <!-- Note: Twitch chat messages must include "?" to be processed as questions -->
             Please type anything in chat! Rate limit is 5 chat messages every minute per user.
             <br/>
             !revive to join the game
        </div>
        <div class="iframe-container">
            <iframe id="displayIframe"
                src="http://localhost:5173"
                width="400" 
                height="400" 
                frameborder="0" 
                scrolling="no"
                style="display: none; border: none; overflow: hidden;">
            </iframe>
        </div>
    </div>

    <div class="top-right">
        <div class="vision-container">
            <img id="uploadedImage" alt="Uploaded image" style="display: none;">
        </div>
    </div>

    <button id="toggleMessageBox">🎮 Toggle UI</button>
    <canvas id="canvas"></canvas>

    <div class="bottom-container">
        <div class="fixed-bottom" id="message"></div>
        <div class="control-buttons">
            <button id="micToggle">🎙️Mic is On</button>
            <button id="interruptBtn">🖐️Voice Interruption On</button>
            <button id="randomModeBtn">🎲Random Mode Off</button>
            <button id="randomVisionBtn">📸Random Vision Off</button>
            <button id="ollamaVisionBtn">👁️Test Vision</button>
            <button id="iframeBtn">🖼️Iframe Off</button>
        </div>
        <div class="user-message-container">
            <span class="user-message-label">You:</span>
            <span class="user-message" id="lastUserMessage">No message yet</span>
        </div>
        <div class="text-input-container">
            <input type="text" id="textInput" placeholder="Type your message here..." />
            <button id="sendButton">Send</button>
        </div>
    </div>

    <!-- <script src="./modelDict.js"></script> -->
    <script src="./live2d.js"></script>

    <script >
        // idle: When the LLM is not thinking or speaking and is waiting for user input.
        // thinking-speaking: When the LLM is thinking or speaking.
        // interrupted: When the LLM is interrupted by the user.


        let state = "idle"; // idle, thinking-speaking, interrupted
        let audioPlayer = new Audio();
        let voiceInterruptionOn = true;
        let fullResponse = ""; // full response from the server in one conversation chain

        const stateDisplay = document.getElementById('stateDisplay');

        function updateStateDisplay() {
            stateDisplay.textContent = `Status: ${state}`;
        }

        function setState(newState) {
            state = newState;
            updateStateDisplay();
        }

        // Update the TaskQueue clearing mechanism
        function clearAllQueues() {
            // Clear both queues immediately
            if (audioTaskQueue) {
                audioTaskQueue.clearQueue();
            }
            if (taskQueue) {
                taskQueue.clearQueue();
            }
            
            // Stop any currently playing audio
            if (audioPlayer) {
                audioPlayer.pause();
                audioPlayer.currentTime = 0;
            }
            
            // Clear any pending audio elements
            const pendingAudios = document.querySelectorAll('audio');
            pendingAudios.forEach(audio => {
                audio.pause();
                audio.remove();
            });
            
            // Reset Live2D model
            if (model2) {
                model2.stopSpeaking();
            }

            // Only hide the image if we're not in random vision mode
            if (!randomVisionMode) {
                const img = document.getElementById('uploadedImage');
                img.style.display = 'none';
            }

            // If random vision is on, restart the timer
            if (randomVisionMode) {
                resetVisionInactivityTimer();
            }
        }

        // Update the interrupt function
        function interrupt() {
            console.log("😡👎 Interrupting conversation chain");
            console.log("Sending: " + JSON.stringify({ type: "interrupt-signal", text: fullResponse }));
            ws.send(JSON.stringify({ type: "interrupt-signal", text: fullResponse }));
            setState("interrupted");
            
            // Clear all queues and stop audio immediately
            clearAllQueues();
            
            // Stop the current audio playback
            if (audioPlayer) {
                audioPlayer.pause();
                audioPlayer.currentTime = 0;
            }
            
            // Stop the Live2D model from speaking
            if (model2) {
                model2.stopSpeaking();
            }
            
            // Clear the message display
            document.getElementById("message").textContent = "";
            
            console.log("Interrupted!!!!");
        }

        let myvad;
        let previousTriggeredProbability = 0; // the possibility that triggered the last speech start
        async function init_vad() {
            myvad = await vad.MicVAD.new({
                preSpeechPadFrames: 10,
                onSpeechStart: () => {
                    console.log("Speech start detected: " + previousTriggeredProbability);
                    if (state === "thinking-speaking" && voiceInterruptionOn) {
                        interrupt();
                    } else {
                        console.log("😀👍 Not interrupted. Just normal conversation");
                    }
                },
                onFrameProcessed: (probs) => {
                    if (probs["isSpeech"] > previousTriggeredProbability) {
                        previousTriggeredProbability = probs["isSpeech"];
                    }
                },
                onVADMisfire: () => {
                    console.log("VAD Misfire. The LLM can't hear you.");
                    document.getElementById("message").textContent = "The LLM can't hear you.";
                },
                onSpeechEnd: (audio) => {
                    if (ws && ws.readyState === WebSocket.OPEN) {
                        sendAudioPartition(audio);
                    }
                }
            });
        }

        const chunkSize = 4096;
        async function sendAudioPartition(audio) {
            console.log(audio)
            // send the audio, a Float32Array of audio samples at sample rate 16000, to the back end by chunks
            for (let index = 0; index < audio.length; index += chunkSize) {
                const endIndex = Math.min(index + chunkSize, audio.length);
                const chunk = audio.slice(index, endIndex);
                ws.send(JSON.stringify({ type: "mic-audio-data", audio: chunk }));
            }
            ws.send(JSON.stringify({ type: "mic-audio-end" }));
            // Update the last user message display for voice input
            document.getElementById("lastUserMessage").textContent = "(Voice Input)";
        }

        // window.addEventListener('load', init_vad);

        // WebSocket connection
        let ws;
        const wsStatus = document.getElementById('wsStatus');
        const wsUrl = document.getElementById('wsUrl');
        const interruptBtn = document.getElementById('interruptBtn');
        const micToggle = document.getElementById('micToggle');

        wsUrl.value = "ws://127.0.0.1:12393/client-ws";
        // if running on server
        if (window.location.protocol.startsWith("http")) {
            console.log("Running on server");
            wsUrl.value = "/client-ws";
        } else { // if running on local using file://
            console.log("Running on local");
        }

        function connectWebSocket() {
            ws = new WebSocket(wsUrl.value);

            ws.onopen = function () {
                // interrupted = false;
                setState("idle");
                console.log("Connected to WebSocket");
                wsStatus.textContent = "Connected";
                wsStatus.classList.add('connected');
            };

            ws.onclose = function () {
                // interrupt = false;
                setState("idle");
                console.log("Disconnected from WebSocket");
                wsStatus.textContent = "Disconnected";
                wsStatus.classList.remove('connected');
                taskQueue.clearQueue();
            };

            ws.onmessage = function (event) {
                handleMessage(JSON.parse(event.data));
            };
        }

        wsStatus.addEventListener('click', connectWebSocket);

        // Update handleMessage to be more strict about interrupted state
        function handleMessage(message) {
            if (state === "interrupted") {
                console.log("Message blocked due to interruption:", message);
                clearAllQueues(); // Ensure queues are clear
                return;
            }
            
            console.log("Received Request: \n", message);
            switch (message.type) {
                case "full-text":
                    document.getElementById("message").textContent = message.text;
                    console.log(message);
                    console.log("full-text: ", message.text);
                    break;
                case "control":
                    switch (message.text) {
                        case "start-mic":
                            // Remove automatic mic start - let user control it manually
                            // start_mic();
                            break;
                        case "stop-mic":
                            stop_mic();
                            break;
                        case "conversation-chain-start":
                            setState("thinking-speaking");
                            fullResponse = "";
                            // Clear any existing inactivity timer when conversation starts
                            if (inactivityTimer) {
                                clearTimeout(inactivityTimer);
                            }
                            break;
                        case "conversation-chain-end":
                            setState("idle");
                            // Start both timers if their respective modes are on
                            if (randomMode) {
                                startInactivityTimer();
                            }
                            if (randomVisionMode) {
                                startVisionInactivityTimer();
                            }
                            // Remove automatic mic start after conversation
                            break;
                    }
                    break;
                case "expression":
                    setExpression(message.text);
                    break;
                case "mouth":
                    setMouth(Number(message.text));
                    break;
                case "audio":
                    if (state == "interrupted") {
                        console.log("Audio playback intercepted. Sentence:", message.text);
                    } else {
                        addAudioTask(message.audio, message.volumes, message.slice_length, message.text, message.expressions);
                        // playAudioLipSync(message.audio, message.volumes, message.slice_length, message.text, message.expressions);
                    }
                    break;
                case "set-model":
                    console.log("set-model: ", message.text);
                    live2dModule.init().then(() => {
                        live2dModule.loadModel(message.text);
                    });
                    break;
                case "listExpressions":
                    console.log(listSupportedExpressions());
                    break;
                case "random-vision-request":
                    // Show loading state
                    const img = document.getElementById('uploadedImage');
                    img.style.display = 'block';
                    // Force reload the image with a timestamp to prevent caching
                    const timestamp = new Date().getTime();
                    img.src = `images/image.jpg?t=${timestamp}`;
                    break;
                case "vision-complete":
                    if (randomVisionMode) {
                        startVisionInactivityTimer();
                    }
                    break;
                default:
                    console.error("Unknown message type: " + message.type);
                    console.log(message);
            }
        }

        // set expression of the model2
        // @param {int} expressionIndex - the expression index defined in the emotionMap in modelDict.js
        function setExpression(expressionIndex) {
            expressionIndex = parseInt(expressionIndex);
            model2.internalModel.motionManager.expressionManager.setExpression(expressionIndex);
            console.info(`>> [x] -> Expression set to: (${expressionIndex})`);
        }

        // [Deprecated] Check if the string contains an expression. If it does, set the expression of the model2.
        // @param {string} str - the string to check
        function checkStringForExpression(str) {
            console.log("emo map: ", emoMap);
            for (const key of Object.keys(emoMap)) {
                if (str.toLowerCase().includes("[" + key + "]")) {
                    console.info(">> [ ] <- add to exec queue: " + key + ", " + emoMap[key]);
                    taskQueue.addTask(() => { setExpression(emoMap[key]); });
                    taskQueue.addTask(() => { console.log("timing out..."); });
                    // setExpression(emoMap[key]);
                }
            }
        }
        // [Deprecated] List all supported expressions
        function listSupportedExpressions() {
            emoMap = model2.internalModel.motionManager.expressionManager.emotionMap;
            console.log(emoMap);
        }



        function setMouth(mouthY) {
            if (typeof model2.internalModel.coreModel.setParameterValueById === 'function') {
                model2.internalModel.coreModel.setParameterValueById('ParamMouthOpenY', mouthY);
            } else {
                model2.internalModel.coreModel.setParamFloat('PARAM_MOUTH_OPEN_Y', mouthY);
            }
        }

        audioTaskQueue = new TaskQueue(100); // 100ms delay between tasks
        // Update addAudioTask to check interrupted state before adding
        function addAudioTask(audio_base64, volumes, slice_length, text = null, expression_list = null) {
            if (state === "interrupted") {
                console.log("Skipping audio task due to interrupted state:", text);
                return;
            }
            
            console.log(`1. Adding audio task ${text} to queue`);

            audioTaskQueue.addTask(async () => {
                return new Promise((resolve, reject) => {
                    if (state === "interrupted") {
                        console.log("Skipping queued audio task due to interrupted state:", text);
                        resolve();
                        return;
                    }

                    // Create a new audio instance for each task
                    const currentAudio = new Audio("data:audio/wav;base64," + audio_base64);
                    
                    currentAudio.onended = () => {
                        console.log(`3. Audio task ${text} completed`);
                        // Clean up
                        currentAudio.src = '';
                        // Check both random modes and hide image if queue is empty
                        if (audioTaskQueue.isEmpty()) {
                            if (randomMode) {
                                resetInactivityTimer();
                            }
                            if (randomVisionMode) {
                                resetVisionInactivityTimer();
                            }
                            // Hide the image when all audio is complete
                            const img = document.getElementById('uploadedImage');
                            img.style.display = 'none';
                        }
                        resolve();
                    };

                    currentAudio.onerror = (error) => {
                        console.error('Audio playback error:', error);
                        reject(error);
                    };

                    playAudioLipSync(currentAudio, volumes, slice_length, text, expression_list);
                });
            });
        }

        async function getAudioLength(audio_base64) {
            return new Promise((resolve) => {
                const audio = new Audio("data:audio/wav;base64," + audio_base64);
                audio.onloadedmetadata = () => {
                    const audioDur = audio.duration * 1000;
                    resolve(audioDur);
                };
            });
        }


        function playAudioLipSync(audioInstance, volumes, slice_length, text = null, expression_list = null) {
            if (state === "interrupted") {
                console.error("Audio playback blocked. Sentence:", text);
                audioTaskQueue.clearQueue();
                return;
            }

            fullResponse += text || "";
            if (text) {
                document.getElementById("message").textContent = text;
            }

            const displayExpression = expression_list ? expression_list[0] : null;
            console.log("Start playing audio: ", text);
            
            try {
                // Play the audio
                const playPromise = audioInstance.play();
                
                if (playPromise !== undefined) {
                    playPromise.catch(error => {
                        console.error("Audio playback failed:", error);
                    });
                }

                // Set the expression and lip sync
                model2.speak(audioInstance.src, { 
                    expression: displayExpression, 
                    resetExpression: false 
                });
            } catch (error) {
                console.error("Error in playAudioLipSync:", error);
            }
        }

        // Start the microphone. This will start the VAD and send audio to the server when speech is detected.
        // Once speech ends, the mic will pause.
        async function start_mic() {
            if (myvad == null) await init_vad();
            console.log("Mic start ");
            try {
                await myvad.start();
                micToggleState = true;
                micToggle.textContent = "🎙️Mic is On";
            } catch (error) {
                console.error("Failed to start microphone:", error);
                micToggleState = false;
                micToggle.textContent = "❌Mic is off";
            }
        }

        function stop_mic() {
            console.log("Mic stop");
            if (myvad) {
                try {
                    myvad.pause();
                } catch (error) {
                    console.error("Error stopping microphone:", error);
                }
            }
            micToggleState = false;
            micToggle.textContent = "❌Mic is off";
        }

        interruptBtn.addEventListener('click', function () {
            voiceInterruptionOn = !voiceInterruptionOn;
            interruptBtn.textContent = voiceInterruptionOn ? "🖐️Voice Interruption On" : "❌Voice Interruption Off";
        });

        let micToggleState = false;
        micToggle.textContent = "❌Mic is off";
        micToggle.addEventListener('click', async function() {
            try {
                if (micToggleState) {
                    stop_mic();
                } else {
                    await start_mic();
                }
            } catch (error) {
                console.error("Error toggling microphone:", error);
                stop_mic(); // Ensure mic is off if there's an error
            }
        });

        // Initialize WebSocket connection
        connectWebSocket();

        const textInput = document.getElementById('textInput');
        const sendButton = document.getElementById('sendButton');

        function sendTextMessage() {
            const message = textInput.value.trim();
            if (message && ws && ws.readyState === WebSocket.OPEN) {
                setState("thinking-speaking");
                ws.send(JSON.stringify({ 
                    type: "text-input", 
                    text: message 
                }));
                // Update the last user message display
                document.getElementById("lastUserMessage").textContent = message;
                textInput.value = ""; // Clear the input box
            }
        }

        // Add event listeners for text input
        textInput.addEventListener('keypress', function(event) {
            if (event.key === "Enter") {
                sendTextMessage();
            }
        });

        sendButton.addEventListener('click', sendTextMessage);


        let randomMode = false;
        let inactivityTimer = null;
        const INACTIVITY_TIMEOUT = 10000; // 10 seconds

        function startInactivityTimer() {
            if (inactivityTimer) {
                clearTimeout(inactivityTimer);
            }
            if (randomMode && state === "idle") {
                inactivityTimer = setTimeout(() => {
                    // Only proceed if we're still idle
                    if (state === "idle") {
                        const randomPrompt = randomPrompts[Math.floor(Math.random() * randomPrompts.length)];
                        textInput.value = randomPrompt;
                        sendTextMessage();
                    }
                }, INACTIVITY_TIMEOUT);
            }
        }

        function resetInactivityTimer() {
            if (inactivityTimer) {
                clearTimeout(inactivityTimer);
            }
            startInactivityTimer();
        }

        // Add this to your existing script section
        const randomModeBtn = document.getElementById('randomModeBtn');
        
        randomModeBtn.addEventListener('click', function() {
            randomMode = !randomMode;
            randomModeBtn.textContent = randomMode ? "🎲Random Mode On" : "🎲Random Mode Off";
            if (randomMode) {
                startInactivityTimer();
            } else {
                clearTimeout(inactivityTimer);
            }
        });

        // Add event listeners to reset timer on user activity
        textInput.addEventListener('keydown', resetInactivityTimer);
        document.addEventListener('mousedown', resetInactivityTimer);
        document.addEventListener('touchstart', resetInactivityTimer);

        // Add the toggle message box functionality to your existing JavaScript
        const toggleMessageBox = document.getElementById('toggleMessageBox');
        const messageBox = document.querySelector('.fixed-bottom');
        const controlButtons = document.querySelector('.control-buttons');
        const textInputContainer = document.querySelector('.text-input-container');
        let uiVisible = true;

        toggleMessageBox.addEventListener('click', function() {
            uiVisible = !uiVisible;
            
            // Get the top-left UI elements
            const topLeftUI = document.querySelector('.top-left');
            
            // Toggle visibility of UI elements EXCEPT the toggle button, twitch notes, and iframe
            [messageBox, controlButtons, textInputContainer].forEach(element => {
                if (element) {
                    element.classList.toggle('ui-hidden');
                }
            });
            
            // Only hide specific elements in top-left, excluding twitch-notes and iframe-container
            if (topLeftUI) {
                Array.from(topLeftUI.children).forEach(child => {
                    if (!child.classList.contains('twitch-notes') && !child.classList.contains('iframe-container')) {
                        child.style.display = uiVisible ? '' : 'none';
                    }
                });
            }
            
            // Update button text
            toggleMessageBox.textContent = uiVisible ? "🎮 Toggle UI" : "👁️ Toggle UI";
        });

        let twitchChat = null;
        const twitchChannel = document.getElementById('twitchChannel');
        const twitchConnect = document.getElementById('twitchConnect');

        // Update the checkAndDisplayImage function to handle both local and URL images
        function checkAndDisplayImage(imageUrl = null) {
            const img = document.getElementById('uploadedImage');
            
            if (imageUrl) {
                // If URL is provided, display directly from URL
                img.src = imageUrl;
            } else {
                // Otherwise use local image.jpg with timestamp
                const timestamp = new Date().getTime();
                img.src = `images/image.jpg?t=${timestamp}`;
            }
            img.style.display = 'block';
        }

        // Update the handleTwitchMessage function to restrict image processing
        function handleTwitchMessage(messageData) {
            console.log(`Twitch message from ${messageData.displayName}: ${messageData.message}`);
            
            // Check if message contains an image URL
            const imageUrlMatch = messageData.message.match(/(https?:\/\/.*\.(?:png|jpg|jpeg|gif))/i);
            
            // Update the last user message display
            document.getElementById("lastUserMessage").textContent = 
                `[Twitch: ${messageData.displayName}] ${messageData.message}`;
            
            if (imageUrlMatch) {
                // Check if the message is from kanipuff (case insensitive)
                if (messageData.displayName.toLowerCase() === 'kanipuff') {
                    const imageUrl = imageUrlMatch[0];
                    console.log('Processing image from kanipuff:', imageUrl);
                    // Display the image directly from URL
                    checkAndDisplayImage(imageUrl);
                    
                    // Send the image URL to the server for processing
                    if (ws && ws.readyState === WebSocket.OPEN) {
                        setState("thinking-speaking");
                        ws.send(JSON.stringify({ 
                            type: "vision-url-request",
                            url: imageUrl,
                            content: "What is in this image? No more than 3 sentences",
                            source: "twitch",
                            username: messageData.displayName
                        }));
                    }
                } else {
                    // Optional: Inform that only kanipuff can share images
                    document.getElementById("message").textContent = "Only kanipuff can share images for processing.";
                }
            } else {
                // Handle regular text message
                if (ws && ws.readyState === WebSocket.OPEN) {
                    setState("thinking-speaking");
                    ws.send(JSON.stringify({ 
                        type: "text-input", 
                        text: messageData.message,
                        source: "twitch",
                        username: messageData.displayName
                    }));
                }
            }
        }

        twitchConnect.addEventListener('click', function() {
            const channel = twitchChannel.value.trim();
            if (channel) {
                if (twitchChat) {
                    twitchChat.disconnect();
                }
                twitchChat = new TwitchChat(channel, handleTwitchMessage);
                twitchChat.connect();
                twitchConnect.textContent = 'Connected to ' + channel;
            }
        });

        const ollamaVisionBtn = document.getElementById('ollamaVisionBtn');
        
        ollamaVisionBtn.addEventListener('click', async function() {
            if (ws && ws.readyState === WebSocket.OPEN) {
                console.log("Sending vision request...");
                
                // Display the image
                checkAndDisplayImage();
                
                // Send vision request
                ws.send(JSON.stringify({
                    type: "vision-request",
                    content: "What is in this image? No more than 3 sentences"
                }));
                
                // Update UI to show request is processing
                document.getElementById("message").textContent = "Processing image...";
            }
        });


        let randomVisionMode = false;
        let visionInactivityTimer = null;
        const VISION_INACTIVITY_TIMEOUT = 15000; // 15 seconds
        const randomVisionBtn = document.getElementById('randomVisionBtn');

        // Function to get a random image from the server
        async function triggerRandomVision() {
            if (ws && ws.readyState === WebSocket.OPEN) {
                console.log("Triggering random vision request...");
                
                // Send request for random image processing
                ws.send(JSON.stringify({
                    type: "random-vision-request",
                    content: "What do you see in this image?"
                }));
                
                // Display the image
                checkAndDisplayImage();
                
                // Update UI to show request is processing
                document.getElementById("message").textContent = "Processing random image...";
            }
        }

        function startVisionInactivityTimer() {
            if (visionInactivityTimer) {
                clearTimeout(visionInactivityTimer);
            }
            if (randomVisionMode && state === "idle") {
                visionInactivityTimer = setTimeout(() => {
                    if (state === "idle") {
                        triggerRandomVision();
                    }
                }, VISION_INACTIVITY_TIMEOUT);
            }
        }

        function resetVisionInactivityTimer() {
            if (visionInactivityTimer) {
                clearTimeout(visionInactivityTimer);
            }
            startVisionInactivityTimer();
        }

        randomVisionBtn.addEventListener('click', function() {
            randomVisionMode = !randomVisionMode;
            randomVisionBtn.textContent = randomVisionMode ? "📸Random Vision On" : "📸Random Vision Off";
            
            if (iframeMode) {
                iframeMode = false;
                iframeBtn.textContent = "🖼️Iframe Off";
                document.getElementById('displayIframe').style.display = 'none';
            }
            
            const img = document.getElementById('uploadedImage');
            if (!randomVisionMode) {
                img.style.display = 'none';
                clearTimeout(visionInactivityTimer);
            } else {
                img.style.display = 'block';
                startVisionInactivityTimer();
                // Trigger first random vision immediately
                triggerRandomVision();
            }
        });

        // Also update the ollamaVisionBtn to check random vision mode
        ollamaVisionBtn.addEventListener('click', async function() {
            if (ws && ws.readyState === WebSocket.OPEN) {
                // Only proceed if random vision is on
                if (!randomVisionMode) {
                    document.getElementById("message").textContent = "Please turn on Random Vision mode first";
                    return;
                }
                
                console.log("Sending vision request...");
                
                // Display the image
                checkAndDisplayImage();
                
                // Send vision request
                ws.send(JSON.stringify({
                    type: "vision-request",
                    content: "What is in this image? No more than 3 sentences"
                }));
                
                // Update UI to show request is processing
                document.getElementById("message").textContent = "Processing image...";
            }
        });

        let iframeMode = false;
        const iframeBtn = document.getElementById('iframeBtn');
        const displayIframe = document.getElementById('displayIframe');

        iframeBtn.addEventListener('click', function() {
            iframeMode = !iframeMode;
            iframeBtn.textContent = iframeMode ? "🖼️Iframe On" : "🖼️Iframe Off";
            
            const iframe = document.getElementById('displayIframe');
            iframe.style.display = iframeMode ? 'block' : 'none';
        });


        // Update checkAndDisplayImage to respect iframe mode
        function checkAndDisplayImage(imageUrl = null) {
            if (!randomVisionMode) return;  // Only show images if random vision is on
            
            const img = document.getElementById('uploadedImage');
            if (imageUrl) {
                img.src = imageUrl;
            } else {
                const timestamp = new Date().getTime();
                img.src = `images/image.jpg?t=${timestamp}`;
            }
            img.style.display = 'block';
        }
    </script>
</body>

</html>