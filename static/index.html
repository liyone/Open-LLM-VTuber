<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Open-LLM-VTuber</title>



    <!-- pixi live2d dependencies -->
    <!-- Load Cubism and PixiJS -->
    <!-- <script src="https://cubism.live2d.com/sdk-web/cubismcore/live2dcubismcore.min.js"></script> -->
    <script src="libs/live2dcubismcore.min.js"></script>
    <!-- <script src="https://cdn.jsdelivr.net/gh/dylanNew/live2d/webgl/Live2D/lib/live2d.min.js"></script> -->
    <script src="libs/live2d.min.js"></script>
    <!-- <script src="https://cdn.jsdelivr.net/npm/pixi.js@7.x/dist/pixi.min.js"></script> -->
    <script src="libs/pixi.min.js"></script>

    <!-- <script src="https://cdn.jsdelivr.net/gh/RaSan147/pixi-live2d-display@v0.5.0-ls-7/dist/index.min.js"></script> -->
    <script src="libs/index.min.js"></script>



    <script src="TaskQueue.js"></script>

    <!-- Voice Activation Detection -->
    <!-- <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/ort.js"></script> -->
    <script src="libs/ort.js"></script>
    <!-- <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.7/dist/bundle.min.js"></script> -->
    <script src="libs/bundle.min.js"></script>

    <link rel="stylesheet" href="index.css">

    <style>
        /* Add these styles to your existing CSS */
        .text-input-container {
            display: flex;
            gap: 10px;
            margin: 15px 0;
            padding: 15px;
        }

        #textInput {
            flex-grow: 1;
            padding: 12px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 30px;
        }

        #sendButton {
            padding: 8px 16px;
            background-color: #4CAF50;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 30px;
        }

        #sendButton:hover {
            background-color: #45a049;
        }

        .user-message-container {
            background-color: rgba(0, 0, 0, 0.6);
            padding: 15px;
            margin: 10px 0;
            border-radius: 4px;
            min-height: 50px;
            max-height: 100px;
            overflow-y: auto;
            font-size: 30px;
        }

        .user-message-label {
            color: #4CAF50;
            font-weight: bold;
            margin-right: 8px;
            font-size: 30px;
        }

        .user-message {
            color: white;
            font-size: 30px;
        }

        /* Update the bot message styles */
        .fixed-bottom {
            min-height: 60px;
            max-height: 120px;
            padding: 15px;
            margin: 10px 0;
            overflow-y: auto;
            background-color: rgba(0, 0, 0, 0.6);
            border-radius: 4px;
            color: white;
            font-size: 40px;
        }
    </style>
</head>

<body>
    <div class="top-left">
        <button id="wsStatus">Disconnected</button>
        <button id="stateDisplay">Status: loading</button>
        <input type="text" id="wsUrl" placeholder="WebSocket URL">
    </div>

    <canvas id="canvas"></canvas>

    <div class="bottom-container">
        <div class="fixed-bottom" id="message"></div>
        <div class="control-buttons">
            <button id="micToggle">üéôÔ∏èMic is On</button>
            <button id="interruptBtn">üñêÔ∏èVoice Interruption On</button>
            <button id="randomModeBtn">üé≤Random Mode Off</button>
        </div>
        <div class="user-message-container">
            <span class="user-message-label">You:</span>
            <span class="user-message" id="lastUserMessage">No message yet</span>
        </div>
        <div class="text-input-container">
            <input type="text" id="textInput" placeholder="Type your message here..." />
            <button id="sendButton">Send</button>
        </div>
    </div>

    <!-- <script src="./modelDict.js"></script> -->
    <script src="./live2d.js"></script>

    <script >
        // idle: When the LLM is not thinking or speaking and is waiting for user input.
        // thinking-speaking: When the LLM is thinking or speaking.
        // interrupted: When the LLM is interrupted by the user.


        let state = "idle"; // idle, thinking-speaking, interrupted
        let audioPlayer = new Audio();
        let voiceInterruptionOn = true;
        let fullResponse = ""; // full response from the server in one conversation chain

        const stateDisplay = document.getElementById('stateDisplay');

        function updateStateDisplay() {
            stateDisplay.textContent = `Status: ${state}`;
        }

        function setState(newState) {
            state = newState;
            updateStateDisplay();
        }

        function interrupt() {
            console.log("üò°üëé Interrupting conversation chain");
            console.log("Sending: " + JSON.stringify({ type: "interrupt-signal", text: fullResponse }))
            ws.send(JSON.stringify({ type: "interrupt-signal", text: fullResponse }));
            setState("interrupted");
            model2.stopSpeaking();
            audioTaskQueue.clearQueue();
            console.log("Interrupted!!!!");
        }

        let myvad;
        let previousTriggeredProbability = 0; // the possibility that triggered the last speech start
        async function init_vad() {
            myvad = await vad.MicVAD.new({
                preSpeechPadFrames: 10,
                onSpeechStart: () => {
                    console.log("Speech start detected: " + previousTriggeredProbability);
                    if (state === "thinking-speaking") {
                        interrupt();
                    } else {
                        console.log("üòÄüëç Not interrupted. Just normal conversation");
                    }
                },
                onFrameProcessed: (probs) => {
                    if (probs["isSpeech"] > previousTriggeredProbability) {
                        previousTriggeredProbability = probs["isSpeech"];
                    }
                },
                onVADMisfire: () => {
                    console.log("VAD Misfire. The LLM can't hear you.");
                    if (state === "interrupted") {
                        state = "idle";
                    }
                    document.getElementById("message").textContent = "The LLM can't hear you.";
                },
                onSpeechEnd: (audio) => {
                    // audio: (Float32Array of audio samples at sample rate 16000)...

                    if (!voiceInterruptionOn) {
                        stop_mic();
                    }

                    if (ws && ws.readyState === WebSocket.OPEN) {
                        sendAudioPartition(audio);
                    }
                }
            });
        }

        const chunkSize = 4096;
        async function sendAudioPartition(audio) {
            console.log(audio)
            // send the audio, a Float32Array of audio samples at sample rate 16000, to the back end by chunks
            for (let index = 0; index < audio.length; index += chunkSize) {
                const endIndex = Math.min(index + chunkSize, audio.length);
                const chunk = audio.slice(index, endIndex);
                ws.send(JSON.stringify({ type: "mic-audio-data", audio: chunk }));
            }
            ws.send(JSON.stringify({ type: "mic-audio-end" }));
            // Update the last user message display for voice input
            document.getElementById("lastUserMessage").textContent = "(Voice Input)";
        }

        // window.addEventListener('load', init_vad);

        // WebSocket connection
        let ws;
        const wsStatus = document.getElementById('wsStatus');
        const wsUrl = document.getElementById('wsUrl');
        const interruptBtn = document.getElementById('interruptBtn');
        const micToggle = document.getElementById('micToggle');

        wsUrl.value = "ws://127.0.0.1:12393/client-ws";
        // if running on server
        if (window.location.protocol.startsWith("http")) {
            console.log("Running on server");
            wsUrl.value = "/client-ws";
        } else { // if running on local using file://
            console.log("Running on local");
        }

        function connectWebSocket() {
            ws = new WebSocket(wsUrl.value);

            ws.onopen = function () {
                // interrupted = false;
                setState("idle");
                console.log("Connected to WebSocket");
                wsStatus.textContent = "Connected";
                wsStatus.classList.add('connected');
            };

            ws.onclose = function () {
                // interrupt = false;
                setState("idle");
                console.log("Disconnected from WebSocket");
                wsStatus.textContent = "Disconnected";
                wsStatus.classList.remove('connected');
                taskQueue.clearQueue();
            };

            ws.onmessage = function (event) {
                handleMessage(JSON.parse(event.data));
            };
        }

        wsStatus.addEventListener('click', connectWebSocket);

        function handleMessage(message) {
            console.log("Received Request: \n", message);
            switch (message.type) {
                case "full-text":
                    document.getElementById("message").textContent = message.text;
                    console.log(message);
                    console.log("full-text: ", message.text);
                    break;
                case "control":
                    switch (message.text) {
                        case "start-mic":
                            start_mic();
                            break;
                        case "stop-mic":
                            stop_mic();
                            break;
                        case "conversation-chain-start":
                            setState("thinking-speaking");
                            fullResponse = "";
                            break;
                        case "conversation-chain-end":
                            setState("idle");
                            if (!voiceInterruptionOn) {
                                start_mic();
                            }
                            startInactivityTimer(); // Restart timer after conversation ends
                            break;
                    }
                    break;
                case "expression":
                    setExpression(message.text);
                    break;
                case "mouth":
                    setMouth(Number(message.text));
                    break;
                case "audio":
                    if (state == "interrupted") {
                        console.log("Audio playback intercepted. Sentence:", message.text);
                    } else {
                        addAudioTask(message.audio, message.volumes, message.slice_length, message.text, message.expressions);
                        // playAudioLipSync(message.audio, message.volumes, message.slice_length, message.text, message.expressions);
                    }
                    break;
                case "set-model":
                    console.log("set-model: ", message.text);
                    live2dModule.init().then(() => {
                        live2dModule.loadModel(message.text);
                    });
                    break;
                case "listExpressions":
                    console.log(listSupportedExpressions());
                    break;
                default:
                    console.error("Unknown message type: " + message.type);
                    console.log(message);
            }
        }

        // set expression of the model2
        // @param {int} expressionIndex - the expression index defined in the emotionMap in modelDict.js
        function setExpression(expressionIndex) {
            expressionIndex = parseInt(expressionIndex);
            model2.internalModel.motionManager.expressionManager.setExpression(expressionIndex);
            console.info(`>> [x] -> Expression set to: (${expressionIndex})`);
        }

        // [Deprecated] Check if the string contains an expression. If it does, set the expression of the model2.
        // @param {string} str - the string to check
        function checkStringForExpression(str) {
            console.log("emo map: ", emoMap);
            for (const key of Object.keys(emoMap)) {
                if (str.toLowerCase().includes("[" + key + "]")) {
                    console.info(">> [ ] <- add to exec queue: " + key + ", " + emoMap[key]);
                    taskQueue.addTask(() => { setExpression(emoMap[key]); });
                    taskQueue.addTask(() => { console.log("timing out..."); });
                    // setExpression(emoMap[key]);
                }
            }
        }
        // [Deprecated] List all supported expressions
        function listSupportedExpressions() {
            emoMap = model2.internalModel.motionManager.expressionManager.emotionMap;
            console.log(emoMap);
        }



        function setMouth(mouthY) {
            if (typeof model2.internalModel.coreModel.setParameterValueById === 'function') {
                model2.internalModel.coreModel.setParameterValueById('ParamMouthOpenY', mouthY);
            } else {
                model2.internalModel.coreModel.setParamFloat('PARAM_MOUTH_OPEN_Y', mouthY);
            }
        }

        audioTaskQueue = new TaskQueue(100); // 100ms delay between tasks
        async function addAudioTask(audio_base64, volumes, slice_length, text = null, expression_list = null) {
            console.log(`1. Adding audio task ${text} to queue`);

            // calculate the total duration of the audio
            audioLength = await getAudioLength(audio_base64);
            console.log(`2. Audio length: ${audioLength}`);

            audioTaskQueue.addTask(async () => {
                playAudioLipSync(audio_base64, volumes, slice_length, text, expression_list);
                await new Promise(resolve => setTimeout(resolve, audioLength));
                console.log(`3. Audio task ${text} completed`);
            });
        }

        async function getAudioLength(audio_base64) {
            return new Promise((resolve) => {
                const audio = new Audio("data:audio/wav;base64," + audio_base64);
                audio.onloadedmetadata = () => {
                    const audioDur = audio.duration * 1000;
                    resolve(audioDur);
                };
            });
        }


        function playAudioLipSync(audio_base64, volumes, slice_length, text = null, expression_list = null) {

            if (state === "interrupted") {
                console.error("Audio playback blocked. Sentence:", text);
                audioTaskQueue.clearQueue();
                return;
            }

            fullResponse += text;
            if (text) {
                document.getElementById("message").textContent = text;
            }

            const displayExpression = expression_list ? expression_list[0] : null;
            console.log("Start playing audio: ", text);
            model2.speak("data:audio/wav;base64," + audio_base64, { expression: displayExpression, resetExpression: false });
        }

        // Start the microphone. This will start the VAD and send audio to the server when speech is detected.
        // Once speech ends, the mic will pause.
        async function start_mic() {
            if (myvad == null) await init_vad();
            console.log("Mic start ");
            myvad.start();
            micToggleState = true;
            micToggle.textContent = "üéôÔ∏èMic is On";
        }

        function stop_mic() {
            console.log("Mic stop");
            myvad.pause();
            micToggleState = false;
            micToggle.textContent = "‚ùåMic is off";
        }

        interruptBtn.addEventListener('click', function () {
            voiceInterruptionOn = !voiceInterruptionOn;
            interruptBtn.textContent = voiceInterruptionOn ? "üñêÔ∏èVoice Interruption On" : "‚ùåVoice Interruption Off";
        });

        let micToggleState = true;
        micToggle.addEventListener('click', function () {
            micToggleState ? stop_mic() : start_mic();
        });

        // Initialize WebSocket connection
        connectWebSocket();

        const textInput = document.getElementById('textInput');
        const sendButton = document.getElementById('sendButton');

        function sendTextMessage() {
            const message = textInput.value.trim();
            if (message && ws && ws.readyState === WebSocket.OPEN) {
                setState("thinking-speaking");
                ws.send(JSON.stringify({ 
                    type: "text-input", 
                    text: message 
                }));
                // Update the last user message display
                document.getElementById("lastUserMessage").textContent = message;
                textInput.value = ""; // Clear the input box
            }
        }

        // Add event listeners for text input
        textInput.addEventListener('keypress', function(event) {
            if (event.key === "Enter") {
                sendTextMessage();
            }
        });

        sendButton.addEventListener('click', sendTextMessage);


        let randomMode = false;
        let inactivityTimer = null;
        const INACTIVITY_TIMEOUT = 10000; // 10 seconds
 // List of random prompts
 const randomPrompts = [
    "How's your day going?",
    "Tell me something interesting.",
    "What do you think about AI?",
    "Do you have any hobbies?",
    "What's your favorite food?",
    "Tell me a joke.",
    "What's the meaning of life?",
    "If you could travel anywhere, where would you go?",
    "What's your favorite book?",
    "Tell me about yourself.",
    "What's your favorite movie and why?",
    "If you could learn any skill instantly, what would it be?",
    "What's a fun fact you recently learned?",
    "What was your dream job as a kid?",
    "What's the best compliment you've ever received?",
    "If you could live in any era, which one would you choose?",
    "What's the most adventurous thing you've done?",
    "Do you believe in aliens?",
    "What's something you want to accomplish this year?",
    "What‚Äôs your favorite way to unwind?",
    "What's a habit you want to start?",
    "What was the last thing you learned to cook?",
    "If you could be famous for one thing, what would it be?",
    "What animal would you choose to be and why?",
    "What's your guilty pleasure song?",
    "If you could meet any historical figure, who would it be?",
    "What's the best piece of advice you've received?",
    "What's something you're proud of?",
    "What's your go-to karaoke song?",
    "If you were a superhero, what would your powers be?",
    "What‚Äôs the best concert you've been to?",
    "What's a hidden talent you have?",
    "What's one place you never want to visit?",
    "If you were a character in a book, who would you be?",
    "What's something you wish you knew more about?",
    "What‚Äôs the funniest thing that happened to you recently?",
    "What's your favorite holiday tradition?",
    "If you could invent something, what would it be?",
    "What's the last show you binge-watched?",
    "What‚Äôs something you've always wanted to try?",
    "What would be your perfect day?",
    "If you could only eat one meal for the rest of your life, what would it be?",
    "What's your spirit animal?",
    "What‚Äôs a topic you could talk about for hours?",
    "What's your favorite way to spend a weekend?",
    "What‚Äôs something that instantly makes you happy?",
    "Do you have any strange phobias?",
    "What's your idea of a perfect vacation?",
    "What's a language you wish you could speak?",
    "What's the most interesting thing about you?",
    "What's your favorite way to spend time outdoors?",
    "What‚Äôs the most memorable gift you've received?",
    "If you could swap lives with anyone, who would it be?",
    "What's a question you wish people asked you more often?",
    "What‚Äôs your favorite childhood memory?",
    "What fictional place would you love to visit?",
    "What‚Äôs your favorite thing to do on a rainy day?",
    "If you had a million dollars, what would you do first?",
    "What‚Äôs the best book you've read this year?",
    "What‚Äôs something you've always wanted to learn?",
    "What‚Äôs your favorite type of weather?",
    "If you could visit any planet, which one would you choose?",
    "What‚Äôs the most interesting conversation you‚Äôve had recently?",
    "What was your favorite toy growing up?",
    "What's a goal you're working towards?",
    "If you had a time machine, what time would you visit?",
    "What‚Äôs the best meal you've ever had?",
    "Do you believe in luck?",
    "What's your favorite part of your daily routine?",
    "If you could have dinner with any fictional character, who would it be?",
    "What‚Äôs a movie that always makes you cry?",
    "If you could only keep five possessions, what would they be?",
    "What's a song you listen to on repeat?",
    "What was your first job?",
    "What's your favorite season and why?",
    "What‚Äôs something you can‚Äôt live without?",
    "What‚Äôs something you wish was never invented?",
    "Do you believe in fate?",
    "What's the last thing you bought that you loved?",
    "If you could redo one day, what would it be?",
    "What's something that instantly cheers you up?",
    "What's the weirdest food combination you enjoy?",
    "What‚Äôs a book that changed your life?",
    "If you could teach a class on any subject, what would it be?",
    "What's the best advice you've ever given?",
    "What‚Äôs something you love to do but are terrible at?",
    "What‚Äôs a small act of kindness that you‚Äôve experienced?",
    "If you could see any artist live, who would it be?",
    "What's a job you think you'd be terrible at?",
    "What's the best prank you've pulled on someone?",
    "What‚Äôs a simple pleasure you enjoy daily?",
    "If you had an extra hour every day, what would you do with it?",
    "What's your biggest pet peeve?",
    "What‚Äôs the most beautiful place you‚Äôve been?",
    "What‚Äôs one trend you just don‚Äôt get?",
    "What's something people misunderstand about you?",
    "If you could only wear one color for a year, what would it be?",
    "What‚Äôs a food you could never get tired of?",
    "What‚Äôs your favorite app on your phone?",
    "What's something you're thankful for today?"
];


        function startInactivityTimer() {
            if (inactivityTimer) {
                clearTimeout(inactivityTimer);
            }
            if (randomMode && state === "idle") {
                inactivityTimer = setTimeout(() => {
                    if (state === "idle") {
                        const randomPrompt = randomPrompts[Math.floor(Math.random() * randomPrompts.length)];
                        textInput.value = randomPrompt;
                        sendTextMessage();
                    }
                }, INACTIVITY_TIMEOUT);
            }
        }

        function resetInactivityTimer() {
            if (inactivityTimer) {
                clearTimeout(inactivityTimer);
            }
            startInactivityTimer();
        }

        // Add this to your existing script section
        const randomModeBtn = document.getElementById('randomModeBtn');
        
        randomModeBtn.addEventListener('click', function() {
            randomMode = !randomMode;
            randomModeBtn.textContent = randomMode ? "üé≤Random Mode On" : "üé≤Random Mode Off";
            if (randomMode) {
                startInactivityTimer();
            } else {
                clearTimeout(inactivityTimer);
            }
        });

        // Add event listeners to reset timer on user activity
        textInput.addEventListener('keydown', resetInactivityTimer);
        document.addEventListener('mousedown', resetInactivityTimer);
        document.addEventListener('touchstart', resetInactivityTimer);
    </script>
</body>

</html>